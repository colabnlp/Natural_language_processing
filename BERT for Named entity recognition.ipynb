{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nfrom tqdm import tqdm, trange\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['ner.csv', 'ner_dataset.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "input_data = pd.read_csv(\"../input/ner_dataset.csv\", encoding=\"latin1\")\n#input_data",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "fa91210f9bc73bfa267e2420780f492d83be7af1"
      },
      "cell_type": "code",
      "source": "input_data = input_data.fillna(method=\"ffill\")\ninput_data.tail(10)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "              Sentence #       Word  POS    Tag\n1048565  Sentence: 47958     impact   NN      O\n1048566  Sentence: 47958          .    .      O\n1048567  Sentence: 47959     Indian   JJ  B-gpe\n1048568  Sentence: 47959     forces  NNS      O\n1048569  Sentence: 47959       said  VBD      O\n1048570  Sentence: 47959       they  PRP      O\n1048571  Sentence: 47959  responded  VBD      O\n1048572  Sentence: 47959         to   TO      O\n1048573  Sentence: 47959        the   DT      O\n1048574  Sentence: 47959     attack   NN      O",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1048565</th>\n      <td>Sentence: 47958</td>\n      <td>impact</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048566</th>\n      <td>Sentence: 47958</td>\n      <td>.</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048567</th>\n      <td>Sentence: 47959</td>\n      <td>Indian</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>1048568</th>\n      <td>Sentence: 47959</td>\n      <td>forces</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048569</th>\n      <td>Sentence: 47959</td>\n      <td>said</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>Sentence: 47959</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>Sentence: 47959</td>\n      <td>responded</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>Sentence: 47959</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>Sentence: 47959</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>Sentence: 47959</td>\n      <td>attack</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef6bcf215604b4247864be63c03e9032f6f558e2"
      },
      "cell_type": "code",
      "source": "words_list = list(set(input_data[\"Word\"].values))\nwords_list[:10]",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "['interviewer',\n 'spiritual',\n 'immunizations',\n 'beating',\n 'lslamic',\n 'Zedong',\n 'respecting',\n '10-to-eight',\n 'rebuke',\n 'starlet']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae74a5b70b9aa9dece4959b80d4bff4a6071e812"
      },
      "cell_type": "code",
      "source": "number_words = len(words_list); number_words",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "35178"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87152fde7e3ea0c671779d932fe1044124e6109c"
      },
      "cell_type": "code",
      "source": "class RetrieveSentance(object):\n    \n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        function = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n                                                           s[\"POS\"].values.tolist(),\n                                                           s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(function)\n        self.sentences = [s for s in self.grouped]\n    \n    def retrieve(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "305b004fd4bd1ef52a4d8bfef554ab326361d946"
      },
      "cell_type": "code",
      "source": "Sentences = RetrieveSentance(input_data)\nSentences",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<__main__.RetrieveSentance at 0x7f1cc2ccff60>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e89d28e02d1bacbce7359347ae94600bb987ee3f"
      },
      "cell_type": "code",
      "source": "Sentences_list = [\" \".join([s[0] for s in sent]) for sent in Sentences.sentences]\nSentences_list[0]",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5d6c76cf541b7c95e0491b4bdae793f0b6aedc8"
      },
      "cell_type": "code",
      "source": "labels = [[s[2] for s in sent] for sent in Sentences.sentences]\nprint(labels[0])",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fea40191f48b48c21e42a6871552919a43a33d22"
      },
      "cell_type": "code",
      "source": "tags2vals = list(set(input_data[\"Tag\"].values))\ntag2idx = {t: i for i, t in enumerate(tags2vals)}",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb9b81a53f7ffbc6a2b2fc46aa9fec336d51a5e9"
      },
      "cell_type": "code",
      "source": "import torch\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_pretrained_bert import BertTokenizer, BertConfig\nfrom pytorch_pretrained_bert import BertForTokenClassification, BertAdam",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b68404b6ffc4879f374b4bd190559aeef94ddce8"
      },
      "cell_type": "code",
      "source": "max_seq_len = 75 # tokens\nbatch_s = 32 # batch size",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a58a0ecf1eb30dcc554a87ab819505dec6d99ef"
      },
      "cell_type": "code",
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5dd0ef060e6d26d1ab695725bbe7a26c8c6f4c1"
      },
      "cell_type": "code",
      "source": "torch.cuda.get_device_name(0) ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'Tesla P100-PCIE-16GB'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc6cd04bb8e9ba1d4bf398ee9fc3af97ad7d0fc3"
      },
      "cell_type": "code",
      "source": "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)\n",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 213450/213450 [00:00<00:00, 1093181.60B/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "963cb752037ba1421031301f54213366d0f808f8"
      },
      "cell_type": "code",
      "source": "tokenized_texts = [tokenizer.tokenize(sent) for sent in Sentences_list]\nprint(tokenized_texts[0])",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'lo', '##ndon', 'to', 'protest', 'the', 'war', 'in', 'i', '##ra', '##q', 'and', 'demand', 'the', 'withdrawal', 'of', 'br', '##itis', '##h', 'troops', 'from', 'that', 'country', '.']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56456d4978d04fac19ffbb0d22a613a0734e4c1c"
      },
      "cell_type": "code",
      "source": "X = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen=max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d42470c504501848fa88fb829f97ce162d80ef6c"
      },
      "cell_type": "code",
      "source": "Y = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=max_seq_len, value=tag2idx[\"O\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41f57a758891a4d9ed7eb444c03583f88aa786ba",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "X",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "array([[ 4674,  1104,  8568, ...,     0,     0,     0],\n       [  178, 23851,  1389, ...,     0,     0,     0],\n       [ 7948,  3832, 12526, ...,     0,     0,     0],\n       ...,\n       [ 1378,   178,  4047, ...,     0,     0,     0],\n       [ 1290,  1173,   117, ...,     0,     0,     0],\n       [ 1103, 10280,  6015, ...,     0,     0,     0]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f7af71fe6b7bbe9ce804fcf1dd4472ca5366fbe"
      },
      "cell_type": "code",
      "source": "Y",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "array([[15, 15, 15, ..., 15, 15, 15],\n       [ 6, 15, 15, ..., 15, 15, 15],\n       [15, 15, 11, ..., 15, 15, 15],\n       ...,\n       [15,  7, 15, ..., 15, 15, 15],\n       [15, 15, 15, ..., 15, 15, 15],\n       [15, 16,  5, ..., 15, 15, 15]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a5204c0bd9f595f24f59c69dba950c3774e359a"
      },
      "cell_type": "code",
      "source": "attention_masks = [[float(i>0) for i in ii] for ii in X]",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64bdffc7ba465fb18a0c46b11daba59b7f86a183"
      },
      "cell_type": "code",
      "source": "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, \n                                                            random_state=20, test_size=0.1)\nMask_train, Mask_valid, _, _ = train_test_split(attention_masks, X,\n                                             random_state=20, test_size=0.1)",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e0d6c5224658787d50addfd5d40bbc602914ee2"
      },
      "cell_type": "code",
      "source": "X_train = torch.tensor(X_train)\nX_valid = torch.tensor(X_valid)\nY_train = torch.tensor(Y_train)\nY_valid = torch.tensor(Y_valid)\nMask_train = torch.tensor(Mask_train)\nMask_valid = torch.tensor(Mask_valid)",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d786b080f7c6f705c8dcd50a7ee6d9acf893b38b"
      },
      "cell_type": "code",
      "source": "data_train = TensorDataset(X_train, Mask_train, Y_train)\ndata_train_sampler = RandomSampler(data_train)\nDL_train = DataLoader(data_train, sampler=data_train_sampler, batch_size=batch_s)\n\ndata_valid = TensorDataset(X_valid, Mask_valid, Y_valid)\ndata_valid_sampler = SequentialSampler(data_valid)\nDL_valid = DataLoader(data_valid, sampler=data_valid_sampler, batch_size=batch_s)",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b7700ca59220d0e07647ee95ae49259fbb77c1a"
      },
      "cell_type": "code",
      "source": "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2idx))",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 404400730/404400730 [00:11<00:00, 35819407.19B/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08f77d24bff1417c049fbfe38cb29dc0fbfe2b71"
      },
      "cell_type": "code",
      "source": "model.cuda();",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f709552931616bc829dba371fb172d1d9d761092"
      },
      "cell_type": "code",
      "source": "FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters()) \n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\noptimizer = Adam(optimizer_grouped_parameters, lr=3e-5)",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3011c3b0a523596d9541f59c5135383b6313f70f"
      },
      "cell_type": "code",
      "source": "from seqeval.metrics import f1_score\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=2).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "896a9673560344c4d5d26deeceae545902ebac19"
      },
      "cell_type": "code",
      "source": "epochs = 5\nmax_grad_norm = 1.0\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    # TRAIN loop\n    model.train()\n    tr_loss = 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    for step, batch in enumerate(DL_train):\n        # add batch to gpu\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        # forward pass\n        loss = model(b_input_ids, token_type_ids=None,\n                     attention_mask=b_input_mask, labels=b_labels)\n        # backward pass\n        loss.backward()\n        # track train loss\n        tr_loss += loss.item()\n        nb_tr_examples += b_input_ids.size(0)\n        nb_tr_steps += 1\n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        # update parameters\n        optimizer.step()\n        model.zero_grad()\n    # print train loss per epoch\n    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n    # VALIDATION on validation set\n    model.eval()\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    predictions , true_labels = [], []\n    for batch in DL_valid:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        \n        with torch.no_grad():\n            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n                                  attention_mask=b_input_mask, labels=b_labels)\n            logits = model(b_input_ids, token_type_ids=None,\n                           attention_mask=b_input_mask)\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n        true_labels.append(label_ids)\n        \n        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n        \n        eval_loss += tmp_eval_loss.mean().item()\n        eval_accuracy += tmp_eval_accuracy\n        \n        nb_eval_examples += b_input_ids.size(0)\n        nb_eval_steps += 1\n    eval_loss = eval_loss/nb_eval_steps\n    print(\"Validation loss: {}\".format(eval_loss))\n    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n    pred_tags = [tags2vals[p_i] for p in predictions for p_i in p]\n    valid_tags = [tags2vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Train loss: 0.04349928928071079\nValidation loss: 0.04484805369128784\nValidation Accuracy: 0.9859369047619049\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch:  20%|██        | 1/5 [07:29<29:56, 449.19s/it]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "F1-Score: 0.7386971097218448\nTrain loss: 0.03685836643021998\nValidation loss: 0.04377520118529598\nValidation Accuracy: 0.9870265873015874\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch:  40%|████      | 2/5 [14:58<22:27, 449.25s/it]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "F1-Score: 0.7590960967815567\nTrain loss: 0.03150499302664671\nValidation loss: 0.04654835322250923\nValidation Accuracy: 0.9861444444444449\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch:  60%|██████    | 3/5 [22:27<14:58, 449.27s/it]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "F1-Score: 0.7504563465562532\nTrain loss: 0.027583255931345665\nValidation loss: 0.04901061260451873\nValidation Accuracy: 0.9862666666666668\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch:  80%|████████  | 4/5 [29:57<07:29, 449.37s/it]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "F1-Score: 0.7546185803942367\nTrain loss: 0.02427265120206264\nValidation loss: 0.04626476022104422\nValidation Accuracy: 0.9877718253968256\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n\n\nEpoch: 100%|██████████| 5/5 [37:26<00:00, 449.33s/it]\u001b[A\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "F1-Score: 0.7769945674134602\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa1b1b6080cae3b837cc93959278b7ad936bb8dc"
      },
      "cell_type": "code",
      "source": "model.eval()\npredictions = []\ntrue_labels = []\neval_loss, eval_accuracy = 0, 0\nnb_eval_steps, nb_eval_examples = 0, 0\nfor batch in DL_valid:\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask, b_labels = batch\n\n    with torch.no_grad():\n        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n                              attention_mask=b_input_mask, labels=b_labels)\n        logits = model(b_input_ids, token_type_ids=None,\n                       attention_mask=b_input_mask)\n        \n    logits = logits.detach().cpu().numpy()\n    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n    label_ids = b_labels.to('cpu').numpy()\n    true_labels.append(label_ids)\n    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n\n    eval_loss += tmp_eval_loss.mean().item()\n    eval_accuracy += tmp_eval_accuracy\n\n    nb_eval_examples += b_input_ids.size(0)\n    nb_eval_steps += 1\n\npred_tags = [[tags2vals[p_i] for p_i in p] for p in predictions]\nvalid_tags = [[tags2vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\nprint(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\nprint(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\nprint(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Validation loss: 0.04626476022104422\nValidation Accuracy: 0.9877718253968256\nValidation F1-Score: 0.7769945674134602\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4dc41595141dfe7c7cabf671ca0dc1eca444d77d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}